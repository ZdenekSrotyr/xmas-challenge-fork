{
  "analysis": "The documentation in docs/keboola/ lacks any information about the Keboola MCP server, which is a key tool for prototyping, validation, and quick data inspection. Users cannot make informed decisions between using MCP tools versus direct Storage API calls. The MCP server is well-documented in role-specific guides (dataapp-developer, component-developer) but this knowledge needs to be in the core keboola documentation that all Claude instances can access.",
  "changes": [
    {
      "file": "docs/keboola/04-mcp-vs-api.md",
      "section": "New file",
      "current": null,
      "proposed": "# MCP Server vs Direct API\n\n## Overview\n\nKeboola provides two ways to interact with the platform programmatically:\n\n1. **Keboola MCP Server** - Interactive tool access via Model Context Protocol\n2. **Storage API** - Direct HTTP API calls for production workloads\n\nThis guide helps you choose the right approach for your use case.\n\n## Quick Decision Guide\n\n| Use Case | Recommended Approach | Why |\n|----------|---------------------|-----|\n| Prototyping / Exploration | **MCP Server** | Interactive, no code needed |\n| Schema validation | **MCP Server** | Quick table inspection |\n| Small data queries (<1000 rows) | **MCP Server** | Fast, no polling |\n| Development/debugging | **MCP Server** | Immediate feedback |\n| Production pipelines | **Storage API** | Full control, error handling |\n| Large datasets (>10K rows) | **Storage API** | Pagination, streaming |\n| Batch processing | **Storage API** | Async jobs, better performance |\n| Scheduled operations | **Storage API** | Reliable, auditable |\n| Complex transformations | **Components** | Versioned, tested, reusable |\n\n## Keboola MCP Server\n\n### What is MCP?\n\nThe Model Context Protocol (MCP) allows AI assistants to access tools for interacting with external systems. The Keboola MCP server provides tools for querying data, inspecting schemas, managing jobs, and more.\n\n**Server URL**: `https://mcp.us-east4.gcp.keboola.com/mcp`\n\n### Available Tools\n\n| Tool | Purpose | Use When |\n|------|---------|----------|\n| `get_project_info` | Get project details and SQL dialect | Starting new project |\n| `list_tables` | Browse available tables | Exploring data |\n| `get_table` | Get table schema and metadata | Validating structure |\n| `query_data` | Execute SQL queries | Small data retrieval |\n| `list_jobs` | Find jobs by status/component | Debugging failures |\n| `get_job` | Get detailed job information | Investigating errors |\n| `run_job` | Execute a component configuration | Testing changes |\n| `get_config` | Inspect component configuration | Validating setup |\n\n### Authentication\n\nThe MCP server uses OAuth authentication. When you first use it:\n\n1. You'll be prompted to authenticate via browser\n2. Authorize the MCP server to access your Keboola projects\n3. Token is cached for future use\n\nNo manual token management needed.\n\n### Example: Validate Table Schema\n\n```\nUse get_table tool with:\n- table_id: \"in.c-main.customers\"\n\nReturns:\n- Fully qualified table name\n- Column names and data types\n- Row count\n- Primary keys\n- Last change timestamp\n```\n\n### Example: Query Sample Data\n\n```\nUse query_data tool with:\n- sql_query: 'SELECT * FROM \"DATABASE\".\"SCHEMA\".\"customers\" LIMIT 10'\n- query_name: \"Sample customer data\"\n\nReturns:\n- Query results as structured data\n- Execution time\n- Row count\n```\n\n### Best Practices for MCP\n\n**DO:**\n- Use for quick validation during development\n- Query small datasets for inspection\n- Check table schemas before writing code\n- Test SQL queries before embedding in applications\n- Debug job failures interactively\n\n**DON'T:**\n- Use for production data pipelines\n- Query large datasets without LIMIT clause\n- Rely on it for scheduled/automated operations\n- Use for batch processing\n- Expect sub-second response times\n\n## Storage API (Direct)\n\n### When to Use\n\nUse direct Storage API calls when you need:\n\n- **Full control**: Custom error handling, retry logic, timeouts\n- **Performance**: Parallel requests, streaming, pagination\n- **Scale**: Large datasets, batch operations\n- **Production reliability**: Proper monitoring, logging, alerting\n- **Integration**: Embed in existing applications\n\n### Authentication\n\n```python\nimport os\nimport requests\n\nSTORAGE_TOKEN = os.environ[\"KEBOOLA_TOKEN\"]\nSTACK_URL = os.environ.get(\"KEBOOLA_STACK_URL\", \"connection.keboola.com\")\n\nheaders = {\n    \"X-StorageApi-Token\": STORAGE_TOKEN,\n    \"Content-Type\": \"application/json\"\n}\n```\n\nSee [Storage API documentation](02-storage-api.md) for complete API reference.\n\n### Example: Production Data Export\n\n```python\nimport requests\nimport time\n\n# Start async export job\nresponse = requests.get(\n    f\"https://{STACK_URL}/v2/storage/tables/{table_id}/export-async\",\n    headers=headers\n)\njob_id = response.json()[\"id\"]\n\n# Poll for completion\nwhile True:\n    job_response = requests.get(\n        f\"https://{STACK_URL}/v2/storage/jobs/{job_id}\",\n        headers=headers\n    )\n    job = job_response.json()\n    \n    if job[\"status\"] == \"success\":\n        file_url = job[\"results\"][\"file\"][\"url\"]\n        data = requests.get(file_url).text\n        break\n    elif job[\"status\"] == \"error\":\n        raise Exception(f\"Job failed: {job['error']['message']}\")\n    \n    time.sleep(2)\n```\n\n### Best Practices for Storage API\n\n**DO:**\n- Implement exponential backoff for rate limits\n- Poll async jobs until completion\n- Use pagination for large datasets\n- Handle all error conditions\n- Log API calls for debugging\n- Validate response status codes\n- Use regional stack URLs from environment\n\n**DON'T:**\n- Hardcode stack URLs\n- Assume operations complete immediately\n- Ignore rate limit errors (429)\n- Skip error handling\n- Load entire large tables into memory\n\nSee [Common Pitfalls](03-common-pitfalls.md) for detailed error handling patterns.\n\n## Combining Both Approaches\n\nThe most effective workflow combines both:\n\n### Development Workflow\n\n1. **Explore with MCP** - Use `list_tables` and `get_table` to discover data\n2. **Prototype with MCP** - Test SQL queries with `query_data`\n3. **Validate with MCP** - Check schemas and sample data\n4. **Build with Storage API** - Implement production code with proper error handling\n5. **Debug with MCP** - Use `list_jobs` and `get_job` to investigate failures\n\n### Example: Building a Data Pipeline\n\n```python\n# Step 1: During development, validate with MCP\n# Use get_table to check:\n# - Table exists\n# - Column names and types\n# - Data volume\n\n# Step 2: Test query with MCP\n# Use query_data with LIMIT 10 to verify SQL syntax\n\n# Step 3: Implement production code with Storage API\ndef extract_customer_data():\n    \"\"\"Production-ready data extraction.\"\"\"\n    try:\n        response = requests.get(\n            f\"https://{STACK_URL}/v2/storage/tables/{table_id}/export-async\",\n            headers=headers,\n            timeout=30\n        )\n        response.raise_for_status()\n        \n        job_id = response.json()[\"id\"]\n        return poll_job_completion(job_id)\n        \n    except requests.exceptions.HTTPError as e:\n        if e.response.status_code == 429:\n            # Handle rate limit\n            time.sleep(60)\n            return extract_customer_data()\n        raise\n    except Exception as e:\n        logging.error(f\"Data extraction failed: {e}\")\n        raise\n\n# Step 4: If issues occur, debug with MCP\n# Use list_jobs to find failed jobs\n# Use get_job to see error details\n```\n\n## Components vs MCP vs API\n\nFor complex, reusable logic, consider building a Keboola component:\n\n| Feature | MCP Server | Storage API | Component |\n|---------|-----------|-------------|------------|\n| Setup complexity | None | Low | High |\n| Code required | No | Yes | Yes |\n| Reusability | Low | Medium | High |\n| Version control | No | Manual | Built-in |\n| Testing | Manual | Manual | Automated |\n| Scheduling | No | External | Built-in |\n| Error handling | Basic | Custom | Robust |\n| Scalability | Low | High | High |\n| Best for | Exploration | Integration | Production |\n\n**Use Components when you need:**\n- Version-controlled, tested logic\n- Scheduled/orchestrated operations\n- Integration with external systems\n- Reusable transformations across projects\n- Team collaboration on data pipelines\n\nSee the Component Developer guides for building custom components.\n\n## Summary\n\n**Start with MCP** for:\n- \u2705 Learning and exploration\n- \u2705 Quick validation and debugging\n- \u2705 Prototyping queries\n- \u2705 Schema inspection\n\n**Move to Storage API** for:\n- \u2705 Production pipelines\n- \u2705 Large-scale data processing\n- \u2705 Custom error handling\n- \u2705 Performance optimization\n\n**Build Components** for:\n- \u2705 Complex, reusable logic\n- \u2705 Scheduled operations\n- \u2705 Team collaboration\n- \u2705 External system integration\n\nThe best approach often uses all three at different stages of development.",
      "reasoning": "Creates comprehensive comparison documentation that addresses all missing elements identified in the test report: MCP server explanation, OAuth setup, available tools, when to use each approach, trade-offs, and decision framework. Includes practical examples and combines information from existing role-specific guides into core documentation."
    },
    {
      "file": "docs/keboola/01-core-concepts.md",
      "section": "After 'Components' section, before 'Authentication'",
      "current": "### Components\nComponents are the building blocks:\n- **Extractors**: Pull data from external sources\n- **Transformations**: Process and modify data\n- **Writers**: Send data to external destinations\n\n## Authentication",
      "proposed": "### Components\nComponents are the building blocks:\n- **Extractors**: Pull data from external sources\n- **Transformations**: Process and modify data\n- **Writers**: Send data to external destinations\n\n### MCP Server\n\nKeboola provides an MCP (Model Context Protocol) server for interactive access to platform features:\n- **Validation**: Check table schemas and data before writing code\n- **Prototyping**: Test SQL queries with small datasets\n- **Debugging**: Inspect jobs and configurations\n- **Exploration**: Browse tables and discover data\n\n**When to use**: Development, debugging, and quick validation tasks.\n\nFor production pipelines and large datasets, use the Storage API directly (see below).\n\nSee [MCP Server vs Direct API](04-mcp-vs-api.md) for detailed comparison and usage guidance.\n\n## Authentication",
      "reasoning": "Introduces MCP server concept in the core concepts document so users are aware of this option early. Brief introduction with pointer to detailed comparison guide."
    },
    {
      "file": "docs/keboola/02-storage-api.md",
      "section": "At the beginning, after the title",
      "current": "# Storage API\n\n## Reading Tables",
      "proposed": "# Storage API\n\n## Overview\n\nThe Storage API provides direct HTTP access to Keboola data and operations. Use it for:\n- Production data pipelines\n- Large-scale data processing\n- Batch operations\n- Custom integrations\n\n**For prototyping and validation**, consider using the [Keboola MCP Server](04-mcp-vs-api.md) instead, which provides interactive tools without writing code.\n\n## Reading Tables",
      "reasoning": "Adds context about when to use Storage API vs MCP server, with a cross-reference to the comparison guide. Helps users make informed decisions from the start."
    },
    {
      "file": "docs/keboola/03-common-pitfalls.md",
      "section": "At the end, after existing pitfalls",
      "current": "## 5. Missing Error Handling\n\n**Problem**: Not handling API errors gracefully\n\n**Solution**: Always check response status:\n\n```python\ndef safe_api_call(url, headers):\n    \"\"\"Make API call with proper error handling.\"\"\"\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n        response.raise_for_status()\n\n        return response.json()\n\n    except requests.exceptions.Timeout:\n        print(\"Request timed out\")\n        return None\n\n    except requests.exceptions.HTTPError as e:\n        if e.response.status_code == 401:\n            print(\"Invalid token\")\n        elif e.response.status_code == 404:\n            print(\"Resource not found\")\n        else:\n            print(f\"HTTP error: {e}\")\n        return None\n\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n```",
      "proposed": "## 5. Missing Error Handling\n\n**Problem**: Not handling API errors gracefully\n\n**Solution**: Always check response status:\n\n```python\ndef safe_api_call(url, headers):\n    \"\"\"Make API call with proper error handling.\"\"\"\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n        response.raise_for_status()\n\n        return response.json()\n\n    except requests.exceptions.Timeout:\n        print(\"Request timed out\")\n        return None\n\n    except requests.exceptions.HTTPError as e:\n        if e.response.status_code == 401:\n            print(\"Invalid token\")\n        elif e.response.status_code == 404:\n            print(\"Resource not found\")\n        else:\n            print(f\"HTTP error: {e}\")\n        return None\n\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n```\n\n## 6. Using Wrong Tool for the Job\n\n**Problem**: Writing complex API code when a simpler solution exists\n\n**Solution**: Consider using the Keboola MCP Server for validation and prototyping:\n\n```python\n# \u274c WRONG - Writing API code to check if a column exists\nimport requests\n\nresponse = requests.get(\n    f\"https://{stack_url}/v2/storage/tables/{table_id}\",\n    headers=headers\n)\ntable_info = response.json()\ncolumn_exists = any(col[\"name\"] == \"customer_id\" for col in table_info[\"columns\"])\n\n# \u2705 BETTER - Use MCP Server for quick validation\n# During development, use get_table tool to check schema\n# Then write production code only for actual data processing\n```\n\n**When to use what:**\n- **MCP Server**: Schema validation, prototyping queries, debugging\n- **Storage API**: Production pipelines, large datasets, batch processing\n- **Components**: Complex logic, scheduled operations, reusable transformations\n\nSee [MCP Server vs Direct API](04-mcp-vs-api.md) for detailed guidance.",
      "reasoning": "Adds a new pitfall about choosing the wrong tool, which was a key missing piece in the test report. Provides concrete examples and cross-references the detailed comparison guide."
    }
  ],
  "pr_title": "docs: Add MCP Server vs Direct API comparison guide",
  "pr_description": "## Summary\n\nAdds comprehensive documentation comparing the Keboola MCP Server with direct Storage API usage, addressing test scenario TS-005.\n\n## Changes\n\n### New Documentation\n\n**`docs/keboola/04-mcp-vs-api.md`** (new file)\n- Decision framework table for choosing between MCP and API\n- Complete MCP server overview with available tools\n- OAuth authentication explanation\n- Storage API production use cases\n- Side-by-side code examples\n- Combined workflow recommendations\n- Components comparison table\n\n### Updated Documentation\n\n**`docs/keboola/01-core-concepts.md`**\n- Added MCP Server subsection introducing the concept\n- Cross-reference to detailed comparison guide\n\n**`docs/keboola/02-storage-api.md`**\n- Added overview section explaining when to use Storage API\n- Cross-reference to MCP comparison for prototyping alternatives\n\n**`docs/keboola/03-common-pitfalls.md`**\n- Added new pitfall #6: \"Using Wrong Tool for the Job\"\n- Guidance on MCP vs API vs Components\n- Cross-reference to comparison guide\n\n## Test Coverage\n\nThis PR addresses all validation criteria from TS-005:\n\n- \u2705 Provides clear decision framework (comparison tables)\n- \u2705 Shows examples of each approach (MCP tools and Storage API)\n- \u2705 Explains trade-offs (performance, scale, complexity)\n- \u2705 Mentions when to combine approaches (development workflow)\n\n## Impact\n\nAfter this change, when users ask Claude:\n- \"Should I use the Keboola MCP server or make direct API calls?\"\n- \"What's the difference between MCP and Storage API?\"\n- \"How do I validate table schemas before writing code?\"\n\nClaude will be able to provide informed guidance based on:\n1. Use case requirements\n2. Data volume\n3. Environment (development vs production)\n4. Complexity needs\n\n## References\n\n- Test Scenario: TS-005\n- Existing MCP documentation: `claude/dataapp-developer/README.md`, `claude/component-developer/guides/debugger/debugging.md`\n- Related: Storage API docs, Common Pitfalls guide"
}