{
  "analysis": "The Keboola Core knowledge file (keboola-core/SKILL.md) is missing documentation for the Jobs API, which is essential for running transformations and other asynchronous operations. While it covers Storage API job polling for exports, it doesn't document how to trigger and monitor transformation jobs, which is a common use case. The dataapp-developer skill references transformation workflows but the core skill lacks the foundational Jobs API knowledge.",
  "changes": [
    {
      "file": "claude/keboola-core/SKILL.md",
      "section": "After 02-storage-api.md section, before 03-common-pitfalls.md",
      "current": null,
      "proposed": "---\n\n<!-- Source: 02b-jobs-api.md -->\n\n# Jobs API\n\n## Overview\n\nThe Jobs API allows you to run and monitor asynchronous operations in Keboola, including:\n- Transformations (SQL, Python, R, Julia)\n- Component configurations (extractors, writers)\n- Data exports and imports\n\nAll Jobs API operations follow the same pattern: create a job, poll for status, retrieve results.\n\n## Running Transformations\n\n### Trigger a Transformation\n\n```python\nimport requests\nimport os\n\nstack_url = os.environ.get(\"KEBOOLA_STACK_URL\", \"connection.keboola.com\")\ntoken = os.environ[\"KEBOOLA_TOKEN\"]\n\n# Run a transformation by its configuration ID\nconfig_id = \"1234567\"  # Your transformation config ID\n\nresponse = requests.post(\n    f\"https://{stack_url}/v2/storage/jobs\",\n    headers={\n        \"X-StorageApi-Token\": token,\n        \"Content-Type\": \"application/json\"\n    },\n    json={\n        \"component\": \"keboola.snowflake-transformation\",\n        \"mode\": \"run\",\n        \"config\": config_id\n    }\n)\n\njob = response.json()\njob_id = job[\"id\"]\nprint(f\"Transformation started: Job ID {job_id}\")\n```\n\n### Monitor Job Status\n\n```python\nimport time\n\ndef wait_for_job(job_id, timeout=600, poll_interval=5):\n    \"\"\"\n    Wait for a job to complete.\n    \n    Args:\n        job_id: The job ID to monitor\n        timeout: Maximum time to wait in seconds (default: 10 minutes)\n        poll_interval: Time between status checks in seconds\n    \n    Returns:\n        dict: Final job details\n    \n    Raises:\n        TimeoutError: If job doesn't complete within timeout\n        Exception: If job fails\n    \"\"\"\n    start_time = time.time()\n    \n    while time.time() - start_time < timeout:\n        response = requests.get(\n            f\"https://{stack_url}/v2/storage/jobs/{job_id}\",\n            headers={\"X-StorageApi-Token\": token}\n        )\n        \n        job = response.json()\n        status = job[\"status\"]\n        \n        print(f\"Job {job_id}: {status}\")\n        \n        if status == \"success\":\n            print(f\"Job completed successfully in {time.time() - start_time:.1f}s\")\n            return job\n        elif status == \"error\":\n            error_msg = job.get(\"result\", {}).get(\"message\", \"Unknown error\")\n            raise Exception(f\"Job {job_id} failed: {error_msg}\")\n        elif status in [\"cancelled\", \"terminated\"]:\n            raise Exception(f\"Job {job_id} was {status}\")\n        \n        # Job still running\n        time.sleep(poll_interval)\n    \n    raise TimeoutError(f\"Job {job_id} did not complete within {timeout}s\")\n\n# Usage\ntry:\n    result = wait_for_job(job_id)\n    print(\"Transformation completed successfully\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n## Running Other Components\n\n### Run an Extractor Configuration\n\n```python\n# Run a data extractor\nresponse = requests.post(\n    f\"https://{stack_url}/v2/storage/jobs\",\n    headers={\n        \"X-StorageApi-Token\": token,\n        \"Content-Type\": \"application/json\"\n    },\n    json={\n        \"component\": \"keboola.ex-db-mysql\",  # Component ID\n        \"mode\": \"run\",\n        \"config\": \"987654\"  # Configuration ID\n    }\n)\n\njob_id = response.json()[\"id\"]\nwait_for_job(job_id)\n```\n\n### Run with Custom Parameters\n\n```python\n# Override configuration parameters at runtime\nresponse = requests.post(\n    f\"https://{stack_url}/v2/storage/jobs\",\n    headers={\n        \"X-StorageApi-Token\": token,\n        \"Content-Type\": \"application/json\"\n    },\n    json={\n        \"component\": \"keboola.snowflake-transformation\",\n        \"mode\": \"run\",\n        \"config\": config_id,\n        \"configData\": {\n            \"parameters\": {\n                \"incremental\": True,\n                \"days_back\": 7\n            }\n        }\n    }\n)\n```\n\n## Job Status and Results\n\n### Understanding Job Status\n\nPossible job statuses:\n- **waiting**: Job queued, not yet started\n- **processing**: Job is currently running\n- **success**: Job completed successfully\n- **error**: Job failed (check error details)\n- **cancelled**: Job was manually cancelled\n- **terminated**: Job was terminated (usually due to timeout)\n- **terminating**: Job is being terminated\n\n### Retrieve Job Results\n\n```python\n# Get detailed job information\nresponse = requests.get(\n    f\"https://{stack_url}/v2/storage/jobs/{job_id}\",\n    headers={\"X-StorageApi-Token\": token}\n)\n\njob = response.json()\n\n# Check execution details\nprint(f\"Status: {job['status']}\")\nprint(f\"Started: {job.get('startTime')}\")\nprint(f\"Ended: {job.get('endTime')}\")\nprint(f\"Duration: {job.get('durationSeconds')}s\")\n\n# For failed jobs, get error details\nif job[\"status\"] == \"error\":\n    error = job.get(\"result\", {})\n    print(f\"Error message: {error.get('message')}\")\n    print(f\"Error type: {error.get('exceptionId')}\")\n    \n    # Some jobs include detailed logs\n    if \"logs\" in job:\n        print(f\"Logs: {job['logs']}\")\n```\n\n## Common Patterns\n\n### Run Multiple Jobs in Sequence\n\n```python\ndef run_job_sequence(jobs_config):\n    \"\"\"\n    Run multiple jobs in sequence.\n    \n    Args:\n        jobs_config: List of job configurations\n        \n    Returns:\n        list: Results from all jobs\n    \"\"\"\n    results = []\n    \n    for i, config in enumerate(jobs_config, 1):\n        print(f\"Running job {i}/{len(jobs_config)}: {config['component']}\")\n        \n        response = requests.post(\n            f\"https://{stack_url}/v2/storage/jobs\",\n            headers={\n                \"X-StorageApi-Token\": token,\n                \"Content-Type\": \"application/json\"\n            },\n            json=config\n        )\n        \n        job_id = response.json()[\"id\"]\n        \n        try:\n            result = wait_for_job(job_id)\n            results.append(result)\n        except Exception as e:\n            print(f\"Job {i} failed: {e}\")\n            raise  # Stop sequence on first failure\n    \n    return results\n\n# Usage\njobs = [\n    {\n        \"component\": \"keboola.ex-db-mysql\",\n        \"mode\": \"run\",\n        \"config\": \"123\"\n    },\n    {\n        \"component\": \"keboola.snowflake-transformation\",\n        \"mode\": \"run\",\n        \"config\": \"456\"\n    }\n]\n\nrun_job_sequence(jobs)\n```\n\n### Run Jobs in Parallel\n\n```python\nimport concurrent.futures\n\ndef run_single_job(job_config):\n    \"\"\"Run a single job and wait for completion.\"\"\"\n    response = requests.post(\n        f\"https://{stack_url}/v2/storage/jobs\",\n        headers={\n            \"X-StorageApi-Token\": token,\n            \"Content-Type\": \"application/json\"\n        },\n        json=job_config\n    )\n    \n    job_id = response.json()[\"id\"]\n    return wait_for_job(job_id)\n\ndef run_jobs_parallel(jobs_config, max_workers=3):\n    \"\"\"\n    Run multiple jobs in parallel.\n    \n    Args:\n        jobs_config: List of job configurations\n        max_workers: Maximum number of parallel jobs\n        \n    Returns:\n        list: Results from all jobs\n    \"\"\"\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = [executor.submit(run_single_job, config) for config in jobs_config]\n        results = []\n        \n        for future in concurrent.futures.as_completed(futures):\n            try:\n                result = future.result()\n                results.append(result)\n            except Exception as e:\n                print(f\"Job failed: {e}\")\n                # Continue processing other jobs\n        \n        return results\n\n# Usage: Run multiple extractors in parallel\njobs = [\n    {\"component\": \"keboola.ex-db-mysql\", \"mode\": \"run\", \"config\": \"123\"},\n    {\"component\": \"keboola.ex-google-analytics\", \"mode\": \"run\", \"config\": \"456\"},\n    {\"component\": \"keboola.ex-salesforce\", \"mode\": \"run\", \"config\": \"789\"}\n]\n\nrun_jobs_parallel(jobs, max_workers=3)\n```\n\n### List Recent Jobs\n\n```python\n# Get list of recent jobs\nresponse = requests.get(\n    f\"https://{stack_url}/v2/storage/jobs\",\n    headers={\"X-StorageApi-Token\": token},\n    params={\n        \"limit\": 50,  # Number of jobs to retrieve\n        \"offset\": 0   # Pagination offset\n    }\n)\n\njobs = response.json()\n\nfor job in jobs:\n    print(f\"{job['id']}: {job['component']} - {job['status']}\")\n```\n\n## Component IDs Reference\n\nCommon component IDs for Jobs API:\n\n**Transformations**:\n- `keboola.snowflake-transformation` - Snowflake SQL\n- `keboola.python-transformation-v2` - Python\n- `keboola.r-transformation` - R\n- `transformation` - Legacy transformations\n\n**Extractors**:\n- `keboola.ex-db-mysql` - MySQL\n- `keboola.ex-db-postgresql` - PostgreSQL\n- `keboola.ex-google-analytics` - Google Analytics\n- `keboola.ex-salesforce` - Salesforce\n\n**Writers**:\n- `keboola.wr-db-mysql` - MySQL\n- `keboola.wr-google-bigquery-v2` - BigQuery\n- `keboola.wr-snowflake` - Snowflake\n\nTo find component IDs in your project, list components:\n```python\nresponse = requests.get(\n    f\"https://{stack_url}/v2/storage/components\",\n    headers={\"X-StorageApi-Token\": token}\n)\n```",
      "reasoning": "Adds comprehensive Jobs API documentation covering the essential use case of running transformations and other components. This fills the gap identified in the issue by providing complete examples of job creation, monitoring, and common patterns that users need when working with Keboola programmatically."
    },
    {
      "file": "claude/keboola-core/SKILL.md",
      "section": "03-common-pitfalls.md, after section 5",
      "current": null,
      "proposed": "\n## 6. Not Handling Job Timeouts\n\n**Problem**: Transformation jobs timing out without proper error handling\n\n**Solution**: Set appropriate timeouts and handle gracefully:\n\n```python\ndef wait_for_job_with_timeout(job_id, timeout=600):\n    \"\"\"\n    Wait for job with proper timeout handling.\n    \n    Different job types have different expected durations:\n    - Simple transformations: 30-60s\n    - Large data extracts: 5-10 minutes\n    - Complex workflows: 10-30 minutes\n    \"\"\"\n    start_time = time.time()\n    poll_interval = 5\n    \n    while time.time() - start_time < timeout:\n        try:\n            response = requests.get(\n                f\"https://{stack_url}/v2/storage/jobs/{job_id}\",\n                headers={\"X-StorageApi-Token\": token},\n                timeout=30  # Request timeout\n            )\n            response.raise_for_status()\n            \n            job = response.json()\n            \n            if job[\"status\"] in [\"success\", \"error\", \"cancelled\", \"terminated\"]:\n                return job\n            \n            time.sleep(poll_interval)\n            \n        except requests.exceptions.Timeout:\n            print(f\"Status check timed out, retrying...\")\n            continue\n        except requests.exceptions.RequestException as e:\n            print(f\"Error checking job status: {e}\")\n            time.sleep(poll_interval)\n    \n    # Timeout reached - try to get final status\n    try:\n        response = requests.get(\n            f\"https://{stack_url}/v2/storage/jobs/{job_id}\",\n            headers={\"X-StorageApi-Token\": token}\n        )\n        job = response.json()\n        raise TimeoutError(\n            f\"Job {job_id} did not complete in {timeout}s. \"\n            f\"Current status: {job.get('status')}. \"\n            f\"Consider increasing timeout or checking job configuration.\"\n        )\n    except requests.exceptions.RequestException:\n        raise TimeoutError(f\"Job {job_id} did not complete in {timeout}s\")\n```\n\n## 7. Using Wrong Component IDs\n\n**Problem**: Job creation fails with \"Component not found\" error\n\n**Solution**: Verify component ID before running:\n\n```python\ndef get_component_configurations(component_id):\n    \"\"\"List all configurations for a component.\"\"\"\n    response = requests.get(\n        f\"https://{stack_url}/v2/storage/components/{component_id}/configs\",\n        headers={\"X-StorageApi-Token\": token}\n    )\n    \n    if response.status_code == 404:\n        print(f\"Component '{component_id}' not found in this project\")\n        return None\n    \n    response.raise_for_status()\n    return response.json()\n\n# Validate before running\ncomponent_id = \"keboola.snowflake-transformation\"\nconfig_id = \"123456\"\n\nconfigs = get_component_configurations(component_id)\nif configs:\n    config_exists = any(c[\"id\"] == config_id for c in configs)\n    if config_exists:\n        # Safe to run\n        run_job(component_id, config_id)\n    else:\n        print(f\"Config {config_id} not found for component {component_id}\")\n```",
      "reasoning": "Adds two common pitfalls specifically related to the Jobs API that users frequently encounter: timeout handling and component ID validation. These complement the existing pitfalls and provide practical solutions to real-world problems."
    },
    {
      "file": "claude/keboola-core/SKILL.md",
      "section": "Overview section - 'When to activate this skill' list",
      "current": "**When to activate this skill:**\n- User asks about Keboola Storage API\n- User needs help with Keboola Jobs API\n- User asks about regional stacks or Stack URLs\n- User encounters Keboola-related errors",
      "proposed": "**When to activate this skill:**\n- User asks about Keboola Storage API\n- User needs help with Keboola Jobs API\n- User wants to run transformations or components programmatically\n- User needs to monitor job execution or handle job errors\n- User asks about regional stacks or Stack URLs\n- User encounters Keboola-related errors",
      "reasoning": "Updates the activation triggers to explicitly mention transformation and job monitoring use cases, making it clearer when this skill should be activated for Jobs API scenarios."
    }
  ],
  "pr_title": "docs: Add comprehensive Jobs API documentation for running transformations",
  "pr_description": "## Summary\nAdds missing Jobs API documentation to the Keboola Core knowledge base, addressing issue TS-003.\n\n## Changes\n\n### New Section: Jobs API (02b-jobs-api.md)\nAdds comprehensive documentation covering:\n- Running transformations programmatically\n- Monitoring job status with proper polling patterns\n- Running other components (extractors, writers)\n- Job status lifecycle and error handling\n- Common patterns (sequential jobs, parallel execution)\n- Component ID reference for common components\n\n### Enhanced Common Pitfalls\nAdds two new pitfalls related to Jobs API:\n- **Pitfall #6**: Not handling job timeouts properly\n- **Pitfall #7**: Using wrong component IDs\n\nBoth include practical solutions and code examples.\n\n### Updated Activation Triggers\nEnhances the \"When to activate this skill\" section to explicitly mention:\n- Running transformations programmatically\n- Monitoring job execution\n- Handling job errors\n\n## Why This Matters\nThe Jobs API is essential for:\n- Automating data pipeline execution\n- Building custom orchestration logic\n- Integrating Keboola into CI/CD workflows\n- Creating data apps that trigger transformations\n\nPreviously, this knowledge was missing from the core skill, requiring users to search external documentation or make assumptions.\n\n## Testing\nDocumentation includes:\n- \u2705 Complete working code examples\n- \u2705 Error handling patterns\n- \u2705 Timeout management\n- \u2705 Both sequential and parallel execution patterns\n- \u2705 Real-world component IDs\n\n## Related\n- Closes TS-003\n- Complements existing Storage API documentation\n- Aligns with dataapp-developer skill references to transformation workflows"
}