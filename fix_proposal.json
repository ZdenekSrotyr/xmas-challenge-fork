{
  "analysis": "The documentation lacks any information about the Keboola MCP server, which is a critical tool for data validation, prototyping, and development workflows. Users need guidance on when to use MCP server tools versus direct Storage API calls. The MCP server provides convenient tools for schema validation, data querying, and quick inspections that are ideal for development and prototyping, while direct API calls are better for production pipelines and batch processing. This guidance needs to be added to the core Keboola documentation.",
  "changes": [
    {
      "file": "docs/keboola/04-mcp-vs-api.md",
      "section": "New file",
      "current": null,
      "proposed": "# MCP Server vs Direct API Usage\n\n## Overview\n\nKeboola provides two primary ways to interact with your data and platform:\n\n1. **Keboola MCP Server** - Interactive tools for development, validation, and prototyping\n2. **Storage API** - Direct HTTP API for production pipelines and batch processing\n\nThis guide helps you choose the right approach for your use case.\n\n## Quick Decision Matrix\n\n| Use Case | Recommended Approach | Why |\n|----------|---------------------|-----|\n| Validating table schemas | MCP Server | Quick inspection without writing code |\n| Prototyping queries | MCP Server | Interactive testing with immediate feedback |\n| Checking data samples | MCP Server | Fast exploration of small datasets |\n| Inspecting job status | MCP Server | Convenient tools for debugging |\n| Production data pipelines | Storage API | Full control, error handling, batch processing |\n| Large dataset exports | Storage API | Handles pagination and async operations |\n| Scheduled/automated tasks | Storage API | Reliable for automation and orchestration |\n| Complex transformations | Components | Built-in error handling and monitoring |\n\n## Keboola MCP Server\n\n### What is MCP?\n\nThe Model Context Protocol (MCP) server provides high-level tools for interacting with Keboola through Claude and other AI assistants. It's designed for:\n- **Development workflows** - Quick validation and prototyping\n- **Data exploration** - Understanding schemas and sample data\n- **Debugging** - Inspecting jobs and configurations\n- **Interactive work** - Ad-hoc queries and analysis\n\n### Available MCP Tools\n\n#### Data Access Tools\n\n**`get_table`** - Get table schema and metadata\n```python\n# Returns: table ID, columns with types, row count, fully qualified name\nmcp__keboola__get_table(table_id=\"in.c-main.customers\")\n```\n\n**`query_data`** - Execute SQL queries\n```python\n# Query with proper dialect (Snowflake, BigQuery, etc.)\nmcp__keboola__query_data(\n    sql_query='SELECT \"customer_id\", COUNT(*) FROM \"DATABASE\".\"SCHEMA\".\"customers\" GROUP BY \"customer_id\" LIMIT 10',\n    query_name=\"Customer count validation\"\n)\n```\n\n**`list_tables`** - Browse available tables\n```python\n# List all tables in a bucket\nmcp__keboola__list_tables(bucket_id=\"in.c-main\")\n```\n\n#### Job Management Tools\n\n**`list_jobs`** - Find jobs by component, status, or config\n```python\nmcp__keboola__list_jobs(\n    component_id=\"keboola.ex-db-mysql\",\n    status=\"error\",\n    limit=10\n)\n```\n\n**`get_job`** - Get detailed job information\n```python\nmcp__keboola__get_job(job_id=\"123456789\")\n```\n\n**`run_job`** - Execute a component configuration\n```python\nmcp__keboola__run_job(\n    component_id=\"keboola.python-transformation-v2\",\n    configuration_id=\"my-config\"\n)\n```\n\n#### Project Tools\n\n**`get_project_info`** - Get project metadata and SQL dialect\n```python\nmcp__keboola__get_project_info()\n# Returns: project ID, name, region, SQL dialect (snowflake/bigquery)\n```\n\n**`search`** - Search for tables and configurations\n```python\nmcp__keboola__search(query=\"customer\")\n```\n\n### MCP Setup\n\n**Authentication**: OAuth flow (automatic)\n1. First use prompts for authentication\n2. Browser opens for OAuth consent\n3. Token stored securely for future use\n\n**Access**: Remote server at `https://mcp.us-east4.gcp.keboola.com/mcp`\n\n**No configuration needed** - Works automatically with Claude Desktop or other MCP-compatible clients.\n\n### When to Use MCP Server\n\n\u2705 **Use MCP Server for:**\n\n1. **Schema Validation**\n   ```python\n   # Before writing code, check what columns exist\n   mcp__keboola__get_table(\"in.c-main.orders\")\n   # \u2192 Verify column names, types, row count\n   ```\n\n2. **Query Prototyping**\n   ```python\n   # Test SQL queries before embedding in code\n   mcp__keboola__query_data(\n       sql_query='SELECT DISTINCT \"status\" FROM \"DB\".\"SCHEMA\".\"orders\"'\n   )\n   # \u2192 Confirm query syntax and results\n   ```\n\n3. **Data Exploration**\n   ```python\n   # Quick look at sample data\n   mcp__keboola__query_data(\n       sql_query='SELECT * FROM \"DB\".\"SCHEMA\".\"customers\" LIMIT 10'\n   )\n   ```\n\n4. **Debugging Jobs**\n   ```python\n   # Find failed jobs\n   mcp__keboola__list_jobs(status=\"error\", limit=5)\n   # Get error details\n   mcp__keboola__get_job(job_id=\"123456789\")\n   ```\n\n5. **Development Workflow**\n   - Validate assumptions before coding\n   - Check data structure changes\n   - Verify filter conditions work\n   - Test component configurations\n\n## Storage API\n\n### What is Storage API?\n\nThe Storage API is Keboola's HTTP REST API for direct programmatic access. It provides:\n- **Full control** over data operations\n- **Async operations** with job polling\n- **Batch processing** capabilities\n- **Production-grade** reliability\n\n### When to Use Storage API\n\n\u2705 **Use Storage API for:**\n\n1. **Production Pipelines**\n   ```python\n   # Automated ETL with error handling\n   response = requests.get(\n       f\"https://{stack_url}/v2/storage/tables/{table_id}/export-async\",\n       headers={\"X-StorageApi-Token\": token}\n   )\n   job_id = response.json()[\"id\"]\n   # Poll until complete, handle errors, retry on failure\n   ```\n\n2. **Large Dataset Operations**\n   ```python\n   # Export millions of rows with pagination\n   def export_table_paginated(table_id, chunk_size=10000):\n       offset = 0\n       while True:\n           chunk = fetch_chunk(table_id, offset, chunk_size)\n           if not chunk:\n               break\n           process_chunk(chunk)\n           offset += chunk_size\n   ```\n\n3. **Batch Processing**\n   ```python\n   # Load multiple tables in parallel\n   import concurrent.futures\n   \n   with concurrent.futures.ThreadPoolExecutor() as executor:\n       futures = [executor.submit(load_table, t) for t in tables]\n       results = [f.result() for f in futures]\n   ```\n\n4. **Scheduled Operations**\n   ```python\n   # Run via cron, Airflow, or other scheduler\n   def daily_sync():\n       # Reliable error handling\n       try:\n           export_data()\n           transform_data()\n           load_data()\n       except Exception as e:\n           alert_team(e)\n           raise\n   ```\n\n5. **Custom Error Handling**\n   ```python\n   # Implement retry logic, circuit breakers, etc.\n   def safe_api_call_with_retry(url, headers, max_retries=3):\n       for attempt in range(max_retries):\n           try:\n               response = requests.get(url, headers=headers)\n               response.raise_for_status()\n               return response.json()\n           except requests.exceptions.HTTPError as e:\n               if e.response.status_code == 429:\n                   time.sleep(2 ** attempt)\n               else:\n                   raise\n   ```\n\n## Combining Both Approaches\n\n### Development Workflow\n\nBest practice: Use MCP for development, Storage API for production\n\n**Phase 1: Explore with MCP**\n```python\n# 1. Check table structure\nmcp__keboola__get_table(\"in.c-main.orders\")\n# \u2192 columns: order_id (INTEGER), status (STRING), amount (FLOAT)\n\n# 2. Test query\nmcp__keboola__query_data(\n    sql_query='SELECT \"status\", COUNT(*) FROM \"DB\".\"SCHEMA\".\"orders\" GROUP BY \"status\"'\n)\n# \u2192 Verify query works, see data distribution\n\n# 3. Validate filters\nmcp__keboola__query_data(\n    sql_query='SELECT * FROM \"DB\".\"SCHEMA\".\"orders\" WHERE \"status\" = \\'shipped\\' LIMIT 5'\n)\n# \u2192 Confirm filter logic before coding\n```\n\n**Phase 2: Implement with Storage API**\n```python\nimport requests\nimport os\n\nstack_url = os.environ[\"KEBOOLA_STACK_URL\"]\ntoken = os.environ[\"KEBOOLA_TOKEN\"]\n\ndef get_shipped_orders():\n    \"\"\"Production function using Storage API.\"\"\"\n    # Export with proper error handling\n    response = requests.get(\n        f\"https://{stack_url}/v2/storage/tables/in.c-main.orders/export-async\",\n        headers={\"X-StorageApi-Token\": token},\n        params={\"whereColumn\": \"status\", \"whereValues\": [\"shipped\"]}\n    )\n    \n    if response.status_code != 200:\n        raise Exception(f\"Export failed: {response.text}\")\n    \n    job_id = response.json()[\"id\"]\n    \n    # Poll with timeout\n    result = wait_for_job(job_id, timeout=300)\n    \n    # Download data\n    file_url = result[\"results\"][\"file\"][\"url\"]\n    data = requests.get(file_url).text\n    \n    return data\n```\n\n### Data App Development\n\nFor Streamlit data apps:\n\n1. **MCP for validation** - Check schemas before building UI\n2. **SQL queries in app** - Use workspace queries for performance\n3. **Storage API for setup** - Initialize tables if needed\n\n```python\n# Development: Validate with MCP\nmcp__keboola__get_table(\"out.c-analytics.metrics\")\n# \u2192 Confirm columns exist\n\n# Production: Query in Streamlit\nimport streamlit as st\nfrom utils.data_loader import execute_query, get_table_name\n\n@st.cache_data(ttl=300)\ndef load_metrics():\n    query = f'''\n        SELECT \"date\", \"metric\", \"value\"\n        FROM {get_table_name()}\n        WHERE \"date\" >= CURRENT_DATE - INTERVAL '30 days'\n        ORDER BY \"date\" DESC\n    '''\n    return execute_query(query)\n```\n\n## API Reference Comparison\n\n### Getting Table Data\n\n**MCP Server:**\n```python\n# Simple, immediate results (up to 1000 rows)\nmcp__keboola__query_data(\n    sql_query='SELECT * FROM \"DB\".\"SCHEMA\".\"table\" LIMIT 100'\n)\n```\n\n**Storage API:**\n```python\n# Async, handles any size, requires polling\nresponse = requests.get(\n    f\"https://{stack_url}/v2/storage/tables/{table_id}/export-async\",\n    headers={\"X-StorageApi-Token\": token}\n)\njob_id = response.json()[\"id\"]\n# Poll job until complete\nresult = wait_for_job(job_id)\nfile_url = result[\"results\"][\"file\"][\"url\"]\ndata = requests.get(file_url).text\n```\n\n### Listing Tables\n\n**MCP Server:**\n```python\n# Returns list with basic info\nmcp__keboola__list_tables(bucket_id=\"in.c-main\")\n```\n\n**Storage API:**\n```python\n# Returns detailed metadata\nresponse = requests.get(\n    f\"https://{stack_url}/v2/storage/buckets/in.c-main/tables\",\n    headers={\"X-StorageApi-Token\": token}\n)\ntables = response.json()\n```\n\n### Running Jobs\n\n**MCP Server:**\n```python\n# Simple execution\nmcp__keboola__run_job(\n    component_id=\"keboola.python-transformation-v2\",\n    configuration_id=\"my-config\"\n)\n```\n\n**Storage API:**\n```python\n# Full control over parameters\nresponse = requests.post(\n    f\"https://{stack_url}/v2/components/{component_id}/configs/{config_id}/run\",\n    headers={\"X-StorageApi-Token\": token},\n    json={\"parameters\": {\"custom\": \"value\"}}\n)\njob_id = response.json()[\"id\"]\n```\n\n## Best Practices\n\n### Do's\n\n\u2705 Use MCP to validate before coding\n\u2705 Use Storage API for production workflows\n\u2705 Combine both: MCP for dev, API for prod\n\u2705 Check schemas with MCP before writing queries\n\u2705 Use MCP for quick debugging and exploration\n\u2705 Use Storage API for reliable batch processing\n\n### Don'ts\n\n\u274c Don't use MCP for production pipelines\n\u274c Don't skip validation when using Storage API\n\u274c Don't use Storage API for simple schema checks\n\u274c Don't ignore error handling in API calls\n\u274c Don't assume MCP query results are production-ready\n\n## Troubleshooting\n\n### MCP Server Issues\n\n**Problem**: \"Authentication required\"\n**Solution**: Re-authenticate through OAuth flow\n\n**Problem**: \"Table not found\"\n**Solution**: Check table ID format: `stage.c-bucket.table`\n\n**Problem**: Query timeout\n**Solution**: Use Storage API for large queries\n\n### Storage API Issues\n\n**Problem**: Job polling timeout\n**Solution**: Increase timeout or use webhooks\n\n**Problem**: Rate limiting (429)\n**Solution**: Implement exponential backoff\n\n**Problem**: Invalid table ID\n**Solution**: Validate format with regex (see Common Pitfalls)\n\n## Summary\n\n**MCP Server** = Development tool for validation, exploration, and debugging\n**Storage API** = Production tool for reliable, scalable data operations\n\nUse both together for the best workflow:\n1. Validate with MCP during development\n2. Implement with Storage API for production\n3. Combine in data apps: MCP for validation, SQL queries for performance",
      "reasoning": "This new file provides comprehensive guidance on when to use MCP server versus direct API calls. It includes clear decision matrices, code examples for both approaches, setup instructions, and best practices for combining both methods. This addresses the test failure by giving users the framework they need to choose the right approach for their use case."
    },
    {
      "file": "docs/keboola/01-core-concepts.md",
      "section": "After 'Authentication' section",
      "current": "## Authentication\n\nUse Storage API tokens for authentication:\n\n```python\nimport os\nimport requests\n\nSTORAGE_TOKEN = os.environ[\"KEBOOLA_TOKEN\"]\nSTACK_URL = os.environ.get(\"KEBOOLA_STACK_URL\", \"connection.keboola.com\")\n\nheaders = {\n    \"X-StorageApi-Token\": STORAGE_TOKEN,\n    \"Content-Type\": \"application/json\"\n}\n\nresponse = requests.get(\n    f\"https://{STACK_URL}/v2/storage/tables\",\n    headers=headers\n)\n```",
      "proposed": "## Authentication\n\nUse Storage API tokens for authentication:\n\n```python\nimport os\nimport requests\n\nSTORAGE_TOKEN = os.environ[\"KEBOOLA_TOKEN\"]\nSTACK_URL = os.environ.get(\"KEBOOLA_STACK_URL\", \"connection.keboola.com\")\n\nheaders = {\n    \"X-StorageApi-Token\": STORAGE_TOKEN,\n    \"Content-Type\": \"application/json\"\n}\n\nresponse = requests.get(\n    f\"https://{STACK_URL}/v2/storage/tables\",\n    headers=headers\n)\n```\n\n## Keboola MCP Server\n\nFor development and prototyping, Keboola provides an MCP (Model Context Protocol) server with interactive tools:\n\n- **Schema validation**: Check table structures without writing code\n- **Query testing**: Prototype SQL queries interactively\n- **Job debugging**: Inspect job status and errors\n- **Data exploration**: Quick data samples and analysis\n\n**Setup**: OAuth authentication (automatic on first use)\n**Access**: Available through Claude Desktop and MCP-compatible tools\n\n**Example MCP tools:**\n```python\n# Get table schema\nmcp__keboola__get_table(\"in.c-main.customers\")\n\n# Test query\nmcp__keboola__query_data(\n    sql_query='SELECT * FROM \"DATABASE\".\"SCHEMA\".\"customers\" LIMIT 10'\n)\n\n# Check job status\nmcp__keboola__get_job(job_id=\"123456789\")\n```\n\n**When to use**: See [MCP Server vs Direct API Usage](04-mcp-vs-api.md) for detailed guidance.\n\n**Note**: MCP is designed for development workflows. For production pipelines, use the Storage API directly.",
      "reasoning": "Adds a brief introduction to MCP server in the core concepts document, making users aware of this alternative approach early on. Keeps it concise with a reference to the detailed comparison document."
    },
    {
      "file": "docs/keboola/03-common-pitfalls.md",
      "section": "Add new section at end",
      "current": "## 5. Missing Error Handling\n\n**Problem**: Not handling API errors gracefully\n\n**Solution**: Always check response status:\n\n```python\ndef safe_api_call(url, headers):\n    \"\"\"Make API call with proper error handling.\"\"\"\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n        response.raise_for_status()\n\n        return response.json()\n\n    except requests.exceptions.Timeout:\n        print(\"Request timed out\")\n        return None\n\n    except requests.exceptions.HTTPError as e:\n        if e.response.status_code == 401:\n            print(\"Invalid token\")\n        elif e.response.status_code == 404:\n            print(\"Resource not found\")\n        else:\n            print(f\"HTTP error: {e}\")\n        return None\n\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n```",
      "proposed": "## 5. Missing Error Handling\n\n**Problem**: Not handling API errors gracefully\n\n**Solution**: Always check response status:\n\n```python\ndef safe_api_call(url, headers):\n    \"\"\"Make API call with proper error handling.\"\"\"\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n        response.raise_for_status()\n\n        return response.json()\n\n    except requests.exceptions.Timeout:\n        print(\"Request timed out\")\n        return None\n\n    except requests.exceptions.HTTPError as e:\n        if e.response.status_code == 401:\n            print(\"Invalid token\")\n        elif e.response.status_code == 404:\n            print(\"Resource not found\")\n        else:\n            print(f\"HTTP error: {e}\")\n        return None\n\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n```\n\n## 6. Using Wrong Tool for the Job\n\n**Problem**: Using Storage API for simple validation or MCP for production pipelines\n\n**Solution**: Choose the right tool:\n\n```python\n# \u274c WRONG - Using API for simple schema check\nresponse = requests.get(\n    f\"https://{stack_url}/v2/storage/tables/{table_id}\",\n    headers={\"X-StorageApi-Token\": token}\n)\ncolumns = [col[\"name\"] for col in response.json()[\"columns\"]]\n\n# \u2705 CORRECT - Use MCP for quick validation\nmcp__keboola__get_table(table_id)\n# \u2192 Immediately see all columns and types\n\n# \u274c WRONG - Using MCP in production pipeline\ndef daily_etl():\n    data = mcp__keboola__query_data(sql_query=\"SELECT * FROM large_table\")\n    # MCP not designed for production/automation\n\n# \u2705 CORRECT - Use Storage API for production\ndef daily_etl():\n    response = requests.get(\n        f\"https://{stack_url}/v2/storage/tables/{table_id}/export-async\",\n        headers={\"X-StorageApi-Token\": token}\n    )\n    job_id = response.json()[\"id\"]\n    result = wait_for_job(job_id)\n    # Reliable, async, handles large datasets\n```\n\n**Quick Guide**:\n- **Development/Validation** \u2192 Use MCP Server\n- **Production/Automation** \u2192 Use Storage API\n- **See**: [MCP Server vs Direct API Usage](04-mcp-vs-api.md)",
      "reasoning": "Adds a new pitfall that directly addresses the issue identified in the test - users not knowing when to use which approach. This provides a quick reference in the pitfalls document with links to the comprehensive guide."
    }
  ],
  "pr_title": "docs: Add MCP Server vs Direct API guidance (TS-005)",
  "pr_description": "## Summary\n\nAdds comprehensive documentation on when to use Keboola MCP Server versus direct Storage API calls, addressing test scenario TS-005.\n\n## Changes\n\n### New Documentation\n\n**`docs/keboola/04-mcp-vs-api.md`** (new file)\n- Complete comparison of MCP server and Storage API approaches\n- Decision matrix for choosing the right tool\n- Setup instructions for MCP server (OAuth)\n- Available MCP tools reference\n- Code examples for both approaches\n- Best practices for combining both methods\n- Side-by-side API comparisons\n- Troubleshooting guide\n\n### Updated Documentation\n\n**`docs/keboola/01-core-concepts.md`**\n- Added \"Keboola MCP Server\" section after Authentication\n- Brief introduction to MCP with key use cases\n- Reference to detailed comparison document\n\n**`docs/keboola/03-common-pitfalls.md`**\n- Added new pitfall #6: \"Using Wrong Tool for the Job\"\n- Examples of incorrect usage patterns\n- Quick decision guide with links\n\n## Test Coverage\n\nThis PR addresses all validation criteria from TS-005:\n\n\u2705 Provides clear decision framework (decision matrix in 04-mcp-vs-api.md)\n\u2705 Shows examples of each approach (MCP and API examples throughout)\n\u2705 Explains trade-offs (performance, reliability, use case sections)\n\u2705 Mentions when to combine approaches (\"Combining Both Approaches\" section)\n\n## Impact\n\nUsers can now:\n- Understand what the Keboola MCP server is\n- Choose between MCP and API confidently\n- Follow best practices for each approach\n- Use MCP for development, API for production\n- Avoid common mistakes in tool selection\n\n## Verification\n\nAfter merging, the Claude skill will be regenerated and will include:\n- MCP server concepts and tools\n- Decision framework for choosing approaches\n- Setup and authentication instructions\n- Combined workflow examples\n\nThis will enable Claude to provide informed guidance when users ask: \"Should I use the Keboola MCP server or make direct API calls?\""
}